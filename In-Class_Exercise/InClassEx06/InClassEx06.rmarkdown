---
title: "In-class Exercise 06"
author: "Jezelei Manangan"
date: "September 23, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  freeze: true
---


# 1.0 Objective & Overview

By the end to this in-ckass exercise, you will be able to:

-   import geospatial data using appropriate function(s) of **sf** package,

-   import csv file using appropriate function of **readr** package,

-   perform relational join using appropriate join function of **dplyr** package,

-   compute spatial weights using appropriate functions of **spdep** package, and

-   calculate spatially lagged variables using appropriate functions of **spdep** package.

-   GWModel

# 2.0 The Study Area and Data

Two data sets will be used in this hands-on exercise, they are:

-   Hunan county boundary layer. This is a geospatial data set in ESRI shapefile format.

-   Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.

Before we get started, we need to ensure that **spdep**, **sf**, **tmap** and **tidyverse** packages of R are currently installed in your R.


```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse)
```


## 2.1 **Import shapefile into R environment**

The code chunk below uses [`st_read()`](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.


```{r}
hunan <- st_read(dsn = "data/geospatial",
                 layer = "Hunan")
```


## 2.2 Import csv file into R environment

Next, we will import *Hunan_2012.csv* into R by using [`read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) of **readr** package. The output is R data frame class.


```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

```{r}
colnames(hunan2012)
```

```{r}
colnames(hunan)
```


## 2.3 Performing Relational Join

The code chunk below will be used to update the attribute table of *hunan*’s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using [`left_join()`](https://dplyr.tidyverse.org/reference/mutate-joins.html) of **dplyr** package.


```{r}
hunan_GDPPC <- left_join(hunan,hunan2012) %>% 
  select(1:4, 7, 15)
```

```{r}

```

```{r}
#hunan <- hunan %>% 
  #select(1:4, 7, 15)
  #select(1:4, 7, 15, 16, 31, 32, 33)
```

```{r}
colnames(hunan)
```


# 3.0 Global Measures of Spatial Autocorrelation

## 3.1 **Computing Contiguity Spatial Weights**


```{r}
wm_q <- hunan_GDPPC %>% 
  mutate(nb = st_contiguity(geometry), 
         wt = st_weights(nb, style="W"),.before = 1)
```


\*st_weights provide tree arguments :


```{r}
wm_q
```


## Computing Global Moran'I


```{r}
moranI <- global_moran(wm_q$GDPPC, 
                       wm_q$nb, 
                       wm_q$wt)
                       
glimpse(moranI)
```


## Performing Global Moran'I test


```{r}
global_moran_test(wm_q$GDPPC, 
                  wm_q$nb, 
                  wm_q$wt)
```


-   p-value : smaller than 0.05. There is enough statistical evidence, 95% confident we can reject the null hypothesis where the observed distribution does not conform to the random distribution

-   Positive Moran I statistic -\> sign of clustering, however at 0.3. It is a relatively low clustering

-   K -\> Average Value of K-Neighbours found

## Performing Global Moran'I permutation test

It is always good to use set.seed() before performing simulation. This is to ensure reproducible computation. You can initialize this from the start


```{r}
set.seed(1234)
```

```{r}
global_moran_perm(wm_q$GDPPC, 
                  wm_q$nb, 
                  wm_q$wt, 
                nsim = 99)
```


-   n=99sim == 100 iterations.

-   The result will be the same.

-   Interpretation of the p-value: Roughly 0.3 Moran –\> stable result compared to the earlier calculation

# Local

## Computing Local Moran'I


```{r}
lisa <- wm_q %>% 
  mutate(local_moran = local_moran(
    GDPPC, nb, wt, nsim=99),
    .before = 1) %>% 
  unnest(local_moran)
```


Unnest() to put back into 1 single tibble table ( 1 - Many ) – You want to make it to one single table, without it, it can't be seen as a data frame

Based on the dataframe results :

-   ii -\> local moran I

P-VALUES

-   p_ii, p_ii_sim, p_folded_sim

    -   p_ii -\> base method

    -   p_ii -\> simulation method

    -   p_folded_sim (pysal method) - using K4 (take out one and leave out 1)

-   use p_ii_sim (simulated)

MEAN, MEDIAN, PYSAL

-   Label Low-Low, High-High & 2 other

-   Compared to Hands-on 6 (you have to manually generate low-low, high-high categorization)

    -   excessive skewness (better to use the median)

    -   if closer to 0 , use mean

-   How do you determine closeness to 0? Very few of them near to 0 -\> Know by plotting it out on a histogram – **refer to skewness as a factor**

    -   no one-row, need to check the majority of the data and go by a mean or median (stay with one based on a classification method)

## Visualizing local Moran's I


```{r}
tmap_mode('plot')
map1 <- tm_shape(lisa) + 
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) + 
  tm_view(set.zoom.limits = c(6,8)) + 
  tm_layout(
    main.title = "local Moran's I of GDPPC", 
    main.title.size = 2)

map1
```


## Visualizing p-value of local Moran's I


```{r}
tmap_mode('plot')
map2 <- tm_shape(lisa) + 
  tm_fill("p_ii_sim") + 
  tm_borders(alpha = 0.5) + 
  tm_view(set.zoom.limits = c(6,8)) + 
  tm_layout(
    main.title = "local Moran's I of GDPPC", 
    main.title.size = 2)

map2
```


Notice that the p value is all over the place, **ideally you need to scale it**

## Visualizing local Moran's I and p-value


```{r}
tmap_mode('plot')
tmap_arrange(map1, map2, ncol=2)
```


## Visualizing LISA Map 


```{r}
lisa_sig <- lisa %>% 
  filter(p_ii < 0.05)

tmap_mode("plot") + 
  tm_shape(lisa) + 
  tm_polygons() + 
  tm_borders(alpha=0.5) + 
  tm_shape(lisa_sig) + 
  tm_fill('mean') + 
  tm_borders(alpha = 0.5)
```


\*Take note: There is a p-value filter there

-   purple - Low GDP area surrounded by high GDP area.


```{=html}
<!-- -->
```

-   Only see this because the rest are not statistically significant

-   Area located near the province and the city - high growth area (Tiering of the Province; Ladder development)

-   Growth spread from the capital (can explore factors accounting for this development)

## Compute local Gi\* statistics


```{r}
wm_idw <- hunan_GDPPC %>% 
  mutate(nb = st_contiguity(geometry), 
         wts = st_inverse_distance(nb, geometry, 
                                   scale=1, 
                                   alpha=1), 
         .before =1)
```


-   The wrapper - the one without the \* (will exclude away the self item)


```{r}
HCSA <- wm_idw %>% 
  mutate(local_Gi = local_gstar_perm(
    GDPPC, nb, wt, nsim =99),
    .before=1) %>% 
  unnest(local_Gi)
HCSA
```


HCSA

-   gi_star, p_value, label (cluster) - statistics to take note of

Similar process to Moran'I \| Gi\* Statistic

LISA - Cluster & Outliers

Gi\* - Hot Spot & Cold Spot

## Visualizing GI\* - Hot Spot & Cold Spot


```{r}
tm_shape(HCSA) + 
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) + 
  tm_view(set.zoom.limits=c(6,8))
```


## p-value


```{r}
HCSA_sig <- HCSA %>% 
  filter(p_sim < 0.05) 

tmap_mode('plot')
tm_shape(HCSA) + 
  tm_polygons() + 
  tm_borders(alpha = 0.5) + 
  
tm_shape(HCSA_sig) + 
  tm_fill("gi_star") + 
  tm_borders(alpha=0.4)
```


-   Can replace gi_star with cluster to visualize the clusters

-   By right, you should map it back to the label


```{r}
HCSA_sig <- HCSA %>% 
  filter(p_sim < 0.05) 

tmap_mode('plot')
tm_shape(HCSA) + 
  tm_polygons() + 
  tm_borders(alpha = 0.5) + 
  
tm_shape(HCSA_sig) + 
  tm_fill("cluster") + 
  tm_borders(alpha=0.4)
```

